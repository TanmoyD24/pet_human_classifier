# Pet vs Human Image Classifier  
Repository: [TanmoyD24/pet_human_classifier](https://github.com/TanmoyD24/pet_human_classifier)

## ğŸ“– Project Overview  
This project is an image-based classifier that predicts whether a given image contains a **pet** or a **human**.  
It demonstrates the workflow of:  
- dataset preparation (images labelled â€œpetâ€ vs â€œhumanâ€)  
- training a deep learning classification model  
- running inference on new images  
- (optionally) evaluating performance metrics  

## ğŸ§© Key Features  
- Simple binary classifier (pet vs human)  
- Pre-processing for images: resizing, normalization, augmentation  
- Model built with [insert framework here: e.g., TensorFlow / PyTorch / Keras]  
- Supports inference of single images or batch processing  
- (Optional) Checkpointing, logging, â–¢ visualization of results  

## ğŸ“‚ Repository Structure  
pet_human_classifier/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train/ â† training images (subfolders: pet/, human/)
â”‚ â”œâ”€â”€ val/ â† validation images
â”‚ â””â”€â”€ test/ â† test images
â”œâ”€â”€ models/ â† saved model checkpoints
â”œâ”€â”€ notebooks/ â† Jupyter notebooks (e.g., training, explorations)
â”œâ”€â”€ src/ â† source code (pre-processing, model definition, inference)
â”œâ”€â”€ inference.py â† script for running inference on new images
â”œâ”€â”€ train.py â† script for training the model
â”œâ”€â”€ requirements.txt â† list of required Python packages
â””â”€â”€ README.md â† (this file)


## ğŸ›  Installation & Setup  
1. Clone the repo:  
   ```bash
   git clone https://github.com/TanmoyD24/pet_human_classifier.git  
   cd pet_human_classifier  
2. Create/activate a virtual environment (optional but recommended):
   python3 -m venv venv  
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`  
   pip install -r requirements.txt  
3. Download or prepare your dataset into the data/ folder as per the structure above

ğŸ“Š Evaluation & Metrics

After training/evaluation you should report key metrics such as:

Accuracy

Precision, Recall, F1-score (for each class)

Confusion Matrix

(Optional) ROC Curve & AUC
Include details of your validation/test split and any caveats (class imbalance, image quality variation, etc).

ğŸ” Model / Architecture Details

Describe here:

Which model architecture you used (e.g., ResNet50/ MobileNet / custom CNN)

Input image size (e.g., 224Ã—224)

Pre-processing steps (normalization, augmentation: flip, rotation, zoom)

Any transfer learning used or training from scratch

Loss function, optimizer, learning rate

Number of parameters, training time, hardware used

How many classes (2: pet / human) and how class labels are encoded

âœ… Results & Findings

Summarise your experiment results:

Training accuracy & loss over epochs

Validation accuracy & loss

Best model checkpoint performance on test set

Sample predictions with images (good and challenging cases)

Any failure/bias cases observed

âš ï¸ Limitations & Future Work

Dataset limitations: e.g., limited variety of pets/humans, lighting/pose issues

Model limitations: over-fitting, generalisation to unseen types

Potential improvements:

More classes (e.g., dog vs cat vs human)

Better augmentation / domain adaptation

Real-time inference / mobile deployment

Explainability (Saliency maps, Grad-CAM)

Larger dataset, improved annotation

ğŸ§ª Contributing

If youâ€™d like to contribute:

Please fork the repository and create a pull request.

Ensure your changes include tests (if applicable) and maintain code style.

Update this README with any new features or dependencies.